#!/usr/bin/Rscript


#   by Jonas Bacelis
#   2014 November
#   CCHMC
#
#   THE META-ANALYSIS SCRIPT FOR PARENTAL-ORIGIN GWAS
#   generates meta-results for each chromosome prunes and saves
#   feeds on per-chr result files (11 tests) generated by Ge's script


##########################################################
##########################################################

# where the output will be directed and named
OUTPUT_PREFIX="/home/joe/Desktop/PARENT_ORIGIN_GWAS_META/meta_results/meta_results_chr"

# which datasets will be used
datasets=c("DNBC","MoBa","HAPO","FIN","GPN")

##########################################################
##########################################################

library(MADAM)   
#library(multicore)  #not implemented yet


for (chr in 1:22) { # for each chromosome extract data, generate and save meta-analysis results
  
  print(paste("CHROMOSOME ", chr,sep=""))

# read-in datasets from various cohrts
for (i in 1:length(datasets)){
  print(paste("  reading file ",i,"...",sep=""))
  # define the file name of results-file from different datasets and different cohorts
  file_name=paste("/data/Joint2/",datasets[i],"/imphap/tab/chr",chr,"/ihap.out",sep="")
  # read-in the result files
  temp=read.table(file_name,header=T,stringsAsFactors=F)
  # save as a new object with easy-to-handle name
  assign(paste("a",i,sep=""),temp)
  rm(temp)
}

#### TEST AN ASSUMPTION that columns are named in exactly same order and follow same naming convention
print("   ...testing assumption that column names in all datasets are identical")
m=matrix(NA,nc=length(datasets),nr=length(datasets)) # column-concordance table ("correlation matrix")
for (i in 1:length(datasets)) { # for each dataset
  for (j in 1:length(datasets)) { # for each dataset
    # extract column names of two datasets
    clnms_set1 = colnames(get(paste("a",i,sep="")))
    clnms_set2 = colnames(get(paste("a",j,sep="")))
    # the following takes care even if datasets are of differing number of columns
    m[i,j]=paste(clnms_set1,collapse="")==paste(clnms_set2,collapse="")
    } }
print(m) # one expects to see all TRUE 
rm(m)

# find the column names of columns containing p-values
pcolixs = grep("pval",colnames(a1))  # P=pval COL=column IXS=indexes
pcolnms = colnames(a1)[pcolixs]  ####  WILL BE USED MANY TIMES IN DOWNSTREAM SCRIPT

# find which rows (SNPs) are "risky", and set those p-values to missing (DO NOT DELETE ROWS!)
for (i in 1:length(datasets)) {
  a=get(paste("a",i,sep=""))  #
  print(paste("   setting NAs for pvals at risky SNPs in file ",i,"...",sep=""))
  badixs1=which( (a$freq<0.03)|(a$freq>0.97)|(a$info<0.6) ) # for all 11 tests
  badixs2=which( (a$t1.test=="fisher")&(a$t2.test=="fisher") ) # only for one (tt) test
  a[badixs1,pcolixs]=NA
  a[badixs2,"tt.pval"]=NA
  assign(paste("a",i,sep=""),a)
  rm(badixs1,badixs2,a)
}

# generate new dataset-unique column names (to avoid problems after merging and facilitate data retreival)
pre_names=colnames(a1)[-2] # save except the "rs" column name (which must be stable while merging)
for (i in 1:length(datasets)) {
  a=get(paste("a",i,sep="")) # temporary copy data
  colnames(a)[-2] =  paste("a",i,".",pre_names,sep="")
  assign(paste("a",i,sep=""),a) # overwrite the old version 
  rm(a)
}


# merge datasets
print("   merging datasets...")
m=get("a1") # get the first dataset (1)
for (i in 2:length(datasets)) { # note that start from 2 !
  print(i)
  a=get(paste("a",i,sep="")) # get new dataset
  m=merge(m,a,by="rs",all=T)
  rm(a)
}
rm(i)

# give new names to 4 most important columns, since other similar ones will be deleted based on their name
colnames(m)[c(1,2,3,4)]=c("SNP","TYPE","CHR","POS")

# report
print(paste("   resulting dimensions: ",paste(dim(m),collapse="  "),sep=""))


print("   pruning to contain only SNPs with minimum pval per all 11*(n-datasets) tests to be < 5e-3...") # ARBITRARY ! ***
# reduce dataset to only "at least one significant p-val per SNP"
cixs = grep("pval",colnames(m)) # C=column IX=index S=plural
fun=function(x) ifelse( sum(is.na(x))==length(cixs), TRUE, min(x,na.rm=T)>5e-3) # 1e-3 is only reasonable to less than 4 studies!
rixs=which(apply(m[,cixs],1,fun)) # generates row indexes that should be removed
m=m[-rixs, ] # reduction of dataset
print(paste("   resulting dimensions: ",paste(dim(m),collapse="  "),sep=""))
rm(rixs,cixs,fun)

print("   recode too large allele names...")
# recode too-long allele names into "L"
ixs=grep(".A|.B",colnames(m)) # IX=index S=plural
for (ix in ixs)   m[which(nchar(m[,ix])>4),ix]="L" # L=LONG    
rm(ixs)

###############  META-ANALYSIS PART
# run the meta-analysis for each test separately
rez=matrix(NA,nr=dim(m)[1],nc=length(pcolnms))  # collector of meta-pvals

for (i in 1:length(pcolnms)) {  # TYPE OF TEST
  print(paste("   meta test ",i,sep=""))
  pmatr=matrix(NA,nc=length(datasets),nr=dim(m)[1]) # the matrix of p values from different cohorts

    for (j in 1:length(datasets)) { # TYPE OF COHORT
      orig_cl_nm = paste("a",j,".",pcolnms[i],sep="") # the original (full merged dataset) column name
      orig_cl_ix = which(colnames(m)==orig_cl_nm) # the original (full merged dataset) column sindex
      pmatr[,j]=m[,orig_cl_ix]
      rm(orig_cl_nm,orig_cl_ix)
    } # end of cycling through cohorts    

  # estimate meta-p only for those SNPs that have more than one present p-value  #### ARBITRARY!!!  CHANGE HERE  ***
  fun=function(x) sum(!is.na(x))>1
  goodrows=which(apply(pmatr,1,fun))
  temp=fisher.method(pmatr[goodrows,],zero.sub = 1e-05,na.rm=T)  # actual Fisher's meta-analysis
  rez[goodrows,i]=temp$p.value
  rm(pmatr,goodrows,temp,fun)
} #end of cycling through tests

meta_names=paste("a0.",pcolnms,sep="")
colnames(rez)=meta_names


# remove unnecessary columns:
badclixs=grep("mid|chr|pos",colnames(m)) # bad columns indexes
out=data.frame(m[,-badclixs],rez)
rm(badclixs,m,rez)

# get rid of some SNPs that do not look promising (to reduce output file sizes)
print("   pruning to contain only SNPs with minimum pval per all 11 meta-tests to be < 1e-4...") # ARBITRARY ! ***
cixs = grep("a0.*.pval",colnames(out)) # C=column IX=index S=plural         
fun=function(x) ifelse( sum(is.na(x))==length(cixs), TRUE, min(x,na.rm=T)>1e-4)                  # ARBITRARY ! ***
rixs=which(apply(out[,cixs],1,fun)) # generates row indexes that should be removed
out=out[-rixs, ] # reduction of dataset
print(paste("   resulting dimensions: ",paste(dim(out),collapse="  "),sep=""))
rm(rixs,cixs,fun)


# save the file for this chromosome
write.table(out,paste(OUTPUT_PREFIX,chr,".txt",sep=""),row.names=F,col.names=T,quote=F,sep="\t")
print("   ... saved.")
rm(rez)

} # end of chromosome cycling

